{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider 2 class classification \n",
    "\n",
    "# Imbalanced Data Set ->  70% postivie and 30% negative\n",
    "# Balanced Data Set -> 50% postivie and 50% negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions for Imbalanced Dataset\n",
    "# Under spamling: Randomly sample some points to get Balanced Dataset\n",
    "\n",
    "Example : 1000 - > 900+ve and 100 -ve\n",
    "Take 100 -ve and take 100+ve from 900 using sampling(take using random)\n",
    "\n",
    "Cons:\n",
    "Throwing 800 points is not a good idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over Smapling: Solution for undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat the under smapled data under the data becomes balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra plotation -> instead of repeat create new artificial points in the region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 vs Rest\n",
    "\n",
    "# Techniqe of converting multi class classfication to binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black Box Models-> They cant give the reasoning\n",
    "\n",
    "Interpretable Model-> Which give the reasoning of output\n",
    "\n",
    "KNN is interpretable if dimensions are small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward feature selection -> select each feature and select features giving more accuray and  after 1st loop select feature and discard feature whose accuracy is almost equal\n",
    "\n",
    "backward feature selection -> select all features and remove whose exlusion is causing bearely decrease in accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Categorial and numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one hot encoding -> encodes the string in to binary vector of the size=no of distinct elements\n",
    "this will be used for categorial feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if no of elements are more once hot encoding will create sparse matrix and very huge vectors.\n",
    "instead take the average class value of the feature of same type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another way is to the domain knowledge which based on the domain knowlege we need to give the ordinal order or value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing values by imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imputation - > replacing missing values \n",
    "\n",
    "mean-> take the mean(of non missing values) and replace missing values\n",
    "impute with mean of respective class label of missing feature\n",
    "new missing value feature-> missing value could be source of information\n",
    "\n",
    "Model based imputation -> move missing values to test data and predict value in test set->model based imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Curse of dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hues phenomen-> performance decrease when the dimensions increase no of datapoints to get good classification\n",
    "Assuming the points are takne by ramdom\n",
    "\n",
    "KNN affected by high dimensions. \n",
    "COSINE will also be affected for high dim but not like KNN\n",
    "\n",
    "SPARSE high dimen better than Dense high dimen values\n",
    "\n",
    "As dimen increases Overfitting increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Generalization error => error on future unseen data => Can we break down in to sume of 3 terms->Bias^2+var + irreducable error\n",
    "\n",
    "Goal of ML is less Generaliazation error\n",
    "\n",
    "irreducable error=>Error that you cannot reduce further. As no model is perfect\n",
    "\n",
    "Bias error => Due to simplifying assumptions\n",
    "    High Bias means(which is more assumptions) -> Under fitting\n",
    "\n",
    "Variance=> how much model changes as the training data changes\n",
    "\n",
    "Model is nothing but a decision surface\n",
    "\n",
    "Incase of KNN -> For k=1 variance is more -> High variance basically mean overfit model\n",
    "\n",
    "\n",
    "Train error is high=> means high bias(because more assumptions)=>Underfit\n",
    "Test error is high => means more variance => Overfit\n",
    "\n",
    "If model changes with small/1 point model has overfitting or high variance problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best cases of KNN \n",
    "dim are less(i.e <20 ) its good \n",
    "\n",
    "KNN should not be used in low latency applications (i.e in fast applications)\n",
    "\n",
    "If we find correct distance measure (for text cosine distance works well,Ecludian distance may not work for gionee data). IF we dont know better avoid KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
