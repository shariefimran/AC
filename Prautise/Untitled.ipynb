{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "con = sqlite3.connect('C:\\\\Users\\\\Mekakris\\\\Documents\\\\AC\\\\Prautise\\\\final.sqlite')\n",
    "\n",
    "data = pd.read_sql_query(\"select * from PractiseCleanedReviews where score!=3\",con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply tfidf and get the standard data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "count_vect = TfidfVectorizer(ngram_range=(1,2))# -> this is for normal text vector\\\n",
    "\n",
    "labels=data['Score'].values\n",
    "\n",
    "final=count_vect.fit_transform(data['Text'].values)\n",
    "standardized_data = StandardScaler(with_mean=False).fit_transform(final)\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the train and the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, x_test, y, y_test = train_test_split(standardized_data,labels,test_size=0.2,train_size=0.8)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x,y,test_size = 0.20,train_size =0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "for k in range(300):\n",
    "    knnmodel=knn(n_neighbors=k+2)\n",
    "\n",
    "    knnmodel.fit(x_train,y_train)\n",
    "\n",
    "    predicted=knnmodel.predict(x_cv)\n",
    "    prob=knnmodel.predict_proba(x_cv)\n",
    "\n",
    "    #print(prob)\n",
    "    #print('k=',k,'Accuracy=',accuracy_score( y_cv,predicted, normalize=False))\n",
    "    \n",
    "    y_cv_temp=[]\n",
    "    predicted_temp=[]\n",
    "    \n",
    "    for a in range(y_cv.shape[0]):\n",
    "        y_cv_temp.append(1 if y_cv[0]=='positive' else 0)\n",
    "        predicted_temp.append(1 if predicted[0]=='positive' else 0)\n",
    "\n",
    "    #print('k=',k,'Precision=',precision_score( y_cv_temp,predicted_temp))\n",
    "    #print('k=',k,'Recall=',recall_score( y_cv_temp,predicted_temp))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN INTERPRETABILITY\n",
    "\n",
    "\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=21)\n",
    "neigh.fit(x_train) \n",
    "\n",
    "NearestNeighbors(algorithm='auto', leaf_size=30)\n",
    "NearestNeighbors(algorithm='auto', leaf_size=30, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Algo\n",
    "\n",
    "    Assuming data has Guassian distribution data we used below\n",
    "    For multinomail distributed data we need to hyper param ALPhA(FIX IS BY CValiadtion)\n",
    "    check for bernouli distributed data also\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.sparse import csr_matrix\n",
    "gnb = GaussianNB()\n",
    "\n",
    "x_train_dense=csr_matrix.todense(x_train)\n",
    "gnb.fit(x_train_dense,y_train)\n",
    "\n",
    "x_cv_dense=csr_matrix.todense(x_cv)\n",
    "\n",
    "\n",
    "\n",
    "predicted=gnb.predict(x_cv_dense)\n",
    "prob=gnb.predict_proba(x_cv_dense)\n",
    "\n",
    "print(accuracy_score( y_cv,predicted, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lgoistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-128ac83babdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0my_cv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as Logistic\n",
    "\n",
    "logr=Logistic()\n",
    "\n",
    "logr.fit(x_train,y_train)\n",
    "\n",
    "predicted=logr.predict(x_cv)\n",
    "prob=logr.predict_proba(x_cv)\n",
    "\n",
    "print(accuracy_score( y_cv,predicted, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact solution is  x = 0                              \n",
      "94\n"
     ]
    }
   ],
   "source": [
    "# Leniar Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as Linear\n",
    "\n",
    "lnr=Linear()\n",
    "\n",
    "y_train_temp=[]\n",
    "for a in range(y_train.shape[0]):\n",
    "    y_train_temp.append(1 if y_train[0]=='positive' else 0)\n",
    "\n",
    "lnr.fit(x_train,y_train_temp)\n",
    "\n",
    "predicted=lnr.predict(x_cv)\n",
    "\n",
    "y_cv_temp=[]\n",
    "for a in range(y_cv.shape[0]):\n",
    "    y_cv_temp.append(1 if y_train[0]=='positive' else 0)\n",
    "\n",
    "print(accuracy_score( y_cv_temp,predicted, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RadomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-16543f0339fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0my_cv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=120,max_depth=5, random_state=100)\n",
    "\n",
    "rf.fit(x_train,y_train)\n",
    "\n",
    "predicted=rf.predict(x_cv)\n",
    "prob=rf.predict_proba(x_cv)\n",
    "\n",
    "print(accuracy_score( y_cv,predicted, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ab=AdaBoostClassifier(base_estimator=None, n_estimators=200, learning_rate=2.0, random_state=None)\n",
    "\n",
    "ab.fit(x_train,y_train)\n",
    "\n",
    "predicted=ab.predict(x_cv)\n",
    "prob=ab.predict_proba(x_cv)\n",
    "\n",
    "print(accuracy_score( y_cv,predicted, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mekakris\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "ab=XGBClassifier()\n",
    "\n",
    "ab.fit(x_train,y_train)\n",
    "\n",
    "predicted=ab.predict(x_cv)\n",
    "prob=ab.predict_proba(x_cv)\n",
    "\n",
    "print(accuracy_score( y_cv,predicted, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm=SVC(kernel='sigmoid')\n",
    "\n",
    "\n",
    "svm.fit(x_train,y_train)\n",
    "\n",
    "predicted=svm.predict(x_cv)\n",
    "\n",
    "\n",
    "print(accuracy_score( y_cv,predicted, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
