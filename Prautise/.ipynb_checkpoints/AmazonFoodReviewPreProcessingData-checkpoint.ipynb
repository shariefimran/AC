{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Amazon Food Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 10)\n"
     ]
    }
   ],
   "source": [
    "con = sqlite3.connect('C:\\\\Users\\\\Mekakris\\\\Documents\\\\AC\\\\amazon-fine-food-reviews-data\\\\database.sqlite')\n",
    "\n",
    "data = pd.read_sql_query(\"select * from reviews where score!=3\",con)\n",
    "\n",
    "data=data[:3000]\n",
    "\n",
    "def parition(x):\n",
    "    if x<3:\n",
    "        return \"negative\"\n",
    "    return \"positive\"\n",
    "\n",
    "actualscore=data['Score']\n",
    "\n",
    "\n",
    "positiveNegative=actualscore.map(parition)\n",
    "data['Score']=positiveNegative\n",
    "\n",
    "print(data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Duplicates from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2991, 10)\n",
      "(588, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "positive    343\n",
       "negative    245\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data=data.sort_values('ProductId',axis=0,ascending=True)\n",
    "\n",
    "# inplace =True will update the existing data frame. False with return a new copy just like below\n",
    "data=data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"},keep=\"first\",inplace=False)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data=data[data.HelpfulnessNumerator<data.HelpfulnessDenominator]\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get English stopwords set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"that'll\", 'shouldn', 'them', 'of', 'i', 'theirs', 'more', 'again', \"mightn't\", 'not', 'than', 'o', 'here', 'been', \"don't\", 'or', 'were', 'same', \"you'd\", 'above', 'where', 'both', 'why', 'am', 'm', 'nor', 'it', 'weren', 'own', 'after', 'all', 'most', 'is', 'into', 'll', 'was', 'too', 'once', 'who', 'wasn', 'this', 'my', 'when', 'himself', 'few', 'under', \"weren't\", 'until', 'hadn', 'by', 'he', 'themselves', 'over', 'didn', \"haven't\", 'won', 'those', 'has', \"didn't\", 'me', \"needn't\", 'an', 'at', 'having', 'each', 'herself', 'your', 're', 'mightn', 'aren', \"hadn't\", 'itself', 'she', 'further', 'our', 'do', \"shouldn't\", 'they', 'below', 'y', 'out', 'yours', 'that', 'there', 'just', \"she's\", 'mustn', \"shan't\", 't', 's', 'in', 'while', 'her', \"couldn't\", 'ours', \"mustn't\", 'ourselves', 'for', 'isn', 'because', 'their', 'haven', \"isn't\", 'hers', 'as', 'had', 'and', 'up', 'how', 'some', \"wouldn't\", 'but', 'during', 'between', 'with', 'being', 'a', 'doesn', 'shan', \"you're\", 'then', 'you', 'to', 'on', 'myself', 'needn', 'its', 'about', 'his', 'if', 'yourselves', \"it's\", 'd', \"you'll\", 'against', 'does', 'yourself', 'be', 'him', 'so', 'these', 've', \"you've\", 'couldn', 'which', 'ain', 'the', 'any', 'wouldn', 'from', 'such', 'are', \"won't\", 'ma', 'will', 'doing', 'no', 'what', \"should've\", 'hasn', 'off', \"hasn't\", 'we', 'through', 'only', \"doesn't\", 'whom', 'have', 'before', 'don', 'did', 'down', 'can', 'very', \"aren't\", 'should', \"wasn't\", 'now', 'other'}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stpwords= set(stopwords.words('english'))\n",
    "\n",
    "print(stpwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some of the words from stopwrod list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stpwords.remove('not')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add words to the stopword list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stpwords)\n",
    "stpwords.add('not')\n",
    "#If we have more stopwrds use stpwords=stpwords.union(urcustomstopwordsset)\n",
    "#print(stpwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove the stopwords and clean html from the review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "sno=nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(sentence): #function to clean the word of any html-tags\\n\",\n",
    "        cleanr = re.compile('<.*?>')\n",
    "        cleantext = re.sub(cleanr, ' ', sentence)\n",
    "        return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\\n\",\n",
    "        cleaned = re.sub(r'[?|!|\\'|\\\"|#]',r'',sentence)\n",
    "        cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "        return  cleaned\n",
    "\n",
    " \n",
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[] # store words from +ve reviews here\\n\",\n",
    "all_negative_words=[] # store words from -ve reviews here.\\n\",\n",
    "s=''\n",
    "\n",
    "#data=data.iloc[0:1000]\n",
    "\n",
    "\n",
    "for sent in data['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    #print(sent);\\n\",\n",
    "    sent=cleanhtml(sent) # remove HTMl tags\\n\",\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if(cleaned_words.lower() not in stpwords):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (data['Score'].values)[i] == 'positive': \n",
    "                        all_positive_words.append(s) #list of all words used to describe positive reviews\\n\",\n",
    "                    if(data['Score'].values)[i] == 'negative':\n",
    "                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\\n\",\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "               continue \n",
    "    #print(filtered_sentence)\\n\",\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\\n\n",
    "    #print(\\\"***********************************************************************\\\")\\n\",\n",
    "    final_string.append(str1)\n",
    "    i+=1\n",
    "\n",
    "    #rint(final_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the preprocessed data in to sql lite for future usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['Text']=final_string\n",
    "\n",
    "\n",
    "# store final table into an SQlLite table for future.\n",
    "conn = sqlite3.connect('final.sqlite')\n",
    "c=conn.cursor()\n",
    "conn.text_factory = str\n",
    "data.to_sql('PractiseCleanedReviews', conn, flavor=None, schema=None, if_exists='replace', index=True, index_label=None, chunksize=None, dtype=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA on the positive and negative review words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(b'chip', 170), (b'like', 147), (b'flavor', 146), (b'tast', 142), (b'good', 135), (b'tea', 106), (b'great', 104), (b'one', 104), (b'love', 104), (b'use', 99), (b'product', 91), (b'make', 85), (b'bag', 78), (b'tri', 74), (b'water', 73), (b'get', 65), (b'realli', 64), (b'amazon', 59), (b'much', 58), (b'potato', 57)]\n",
      "[(b'like', 142), (b'tast', 138), (b'chip', 131), (b'product', 125), (b'one', 103), (b'flavor', 99), (b'bag', 98), (b'food', 86), (b'tri', 74), (b'good', 72), (b'use', 70), (b'would', 65), (b'drink', 64), (b'water', 63), (b'eat', 62), (b'order', 61), (b'buy', 58), (b'much', 58), (b'tea', 58), (b'get', 56)]\n",
      "b'chip'           170\n",
      "b'like'           147\n",
      "b'flavor'         146\n",
      "b'tast'           142\n",
      "b'good'           135\n",
      "b'tea'            106\n",
      "b'great'          104\n",
      "b'love'           104\n",
      "b'one'            104\n",
      "b'use'             99\n",
      "b'product'         91\n",
      "b'make'            85\n",
      "b'bag'             78\n",
      "b'tri'             74\n",
      "b'water'           73\n",
      "b'get'             65\n",
      "b'realli'          64\n",
      "b'amazon'          59\n",
      "b'much'            58\n",
      "b'find'            57\n",
      "b'potato'          57\n",
      "b'time'            56\n",
      "b'price'           54\n",
      "b'buy'             54\n",
      "b'sweet'           54\n",
      "b'would'           52\n",
      "b'drink'           52\n",
      "b'also'            51\n",
      "b'eat'             51\n",
      "b'order'           50\n",
      "                 ... \n",
      "b'reviewd'          1\n",
      "b'meant'            1\n",
      "b'imo'              1\n",
      "b'superb'           1\n",
      "b'trap'             1\n",
      "b'noteworthi'       1\n",
      "b'airtight'         1\n",
      "b'carm'             1\n",
      "b'whistl'           1\n",
      "b'upc'              1\n",
      "b'monster'          1\n",
      "b'taken'            1\n",
      "b'inquiri'          1\n",
      "b'resourc'          1\n",
      "b'substanti'        1\n",
      "b'cart'             1\n",
      "b'hibiscus'         1\n",
      "b'dop'              1\n",
      "b'onioni'           1\n",
      "b'lord'             1\n",
      "b'drain'            1\n",
      "b'orac'             1\n",
      "b'suffer'           1\n",
      "b'second'           1\n",
      "b'gallo'            1\n",
      "b'guilt'            1\n",
      "b'seven'            1\n",
      "b'appet'            1\n",
      "b'dressingnow'      1\n",
      "b'gradual'          1\n",
      "Name: pos, Length: 2564, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "most_positive= nltk.FreqDist(all_positive_words)\n",
    "most_negative= nltk.FreqDist(all_negative_words)\n",
    "\n",
    "print(most_positive.most_common(20))\n",
    "print(most_negative.most_common(20))\n",
    "\n",
    "# same analysis using positive and negative words\n",
    "df=pd.DataFrame({'pos':all_positive_words})\n",
    "#print(df['pos'].value_counts(ascending =False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
